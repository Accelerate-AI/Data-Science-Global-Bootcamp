{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AccelerateAI: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with sklearn vs statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a synthetic data randomly generated and will compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random numbers with seed set for consistency\n",
    "random_generator = np.random.default_rng(seed=124)\n",
    "\n",
    "# Create an array with 600 rows and 3 columns\n",
    "X_for_creating_probabilities = random_generator.normal(size=(600,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30062, -0.57846, -1.11057],\n",
       "       [-1.18548,  0.81149,  0.60825],\n",
       "       [-1.02757,  1.08403, -0.4984 ],\n",
       "       [ 1.11852, -1.22129,  0.24011],\n",
       "       [-1.91692,  0.07204,  1.0028 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_for_creating_probabilities[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create an array with first column removed. The removed column can be thought of as random noise OR as a feature that we do not have access to while creating the model. In real life scenarios, this could typically be a case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57846, -1.11057],\n",
       "       [ 0.81149,  0.60825],\n",
       "       [ 1.08403, -0.4984 ],\n",
       "       [-1.22129,  0.24011],\n",
       "       [ 0.07204,  1.0028 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.delete(X_for_creating_probabilities,0,axis=1)\n",
    "\n",
    "X1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add 2 features/columns correlated with X1. Practical datasets often have highly correlated features. Correlation increases the likelihood of overfitting. We will concatenate these 2 new features to firm up a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X1 + 0.1 * np.random.normal(size=(600,2))\n",
    "\n",
    "X_predictors = np.concatenate((X1,X2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57846, -1.11057, -0.5971 , -1.05121],\n",
       "       [ 0.81149,  0.60825,  0.92463,  0.55305],\n",
       "       [ 1.08403, -0.4984 ,  1.16891, -0.47691],\n",
       "       [-1.22129,  0.24011, -1.12678,  0.25713],\n",
       "       [ 0.07204,  1.0028 ,  0.00452,  1.02345]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predictors[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create our outcome/target feature and have it related to ```X_predictors```. In order to accomplish that, we will use our data as inputs to the logistic regression to get probabilities. Then, we can set our outcome feature to ```TRUE``` when probability is above 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5183333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prob = 1 / (1 + np.e**(-np.matmul(X_for_creating_probabilities,[1,1,1])))\n",
    "\n",
    "Y = Prob > 0.5\n",
    "\n",
    "np.mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the data to TRAIN and TEST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:330  X_test:270\n"
     ]
    }
   ],
   "source": [
    "k=330\n",
    "\n",
    "X_train = X_predictors[:k]\n",
    "y_train = Y[:k]\n",
    "\n",
    "X_test = X_predictors[k:]\n",
    "y_test = Y[k:]\n",
    "\n",
    "print(f\"X_train:{len(X_train)}  X_test:{len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:[-0.10917]  Coefficients: [[0.78477 1.36389 0.87383 0.39505]]\n",
      "Train Accuracy:0.8121212121212121\n",
      "Test Accuracy:0.7851851851851852\n"
     ]
    }
   ],
   "source": [
    "# sklearn LR applies regularization by default\n",
    "sklearn_default = LogisticRegression(random_state=124).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Intercept:{sklearn_default.intercept_}  Coefficients: {sklearn_default.coef_}\")\n",
    "print(f\"Train Accuracy:{sklearn_default.score(X_train,y_train)}\")\n",
    "print(f\"Test Accuracy:{sklearn_default.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn off regularization by setting ```penalty=none```. Applying regularization reduces the magnitude of coefficients. Setting the penalty to none will increase the value of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:[-0.14249]  Coefficients: [[ 0.54707  3.72311  1.21029 -1.83822]]\n",
      "Train Accuracy:0.8151515151515152\n",
      "Test Accuracy:0.7962962962962963\n"
     ]
    }
   ],
   "source": [
    "# sklearn LR with no penalty\n",
    "sklearn_no_penalty = LogisticRegression(random_state=124,penalty='none').fit(X_train, y_train)\n",
    "\n",
    "print(f\"Intercept:{sklearn_no_penalty.intercept_}  Coefficients: {sklearn_no_penalty.coef_}\")\n",
    "print(f\"Train Accuracy:{sklearn_no_penalty.score(X_train,y_train)}\")\n",
    "print(f\"Test Accuracy:{sklearn_no_penalty.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above scenario, ```C=1.0``` is set by default. Smaller values of C increase the regularization. So let's say if we set ```C=0.1``` then magnitude of coefficients reduces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:[-0.07565]  Coefficients: [[0.66188 0.76325 0.67581 0.6625 ]]\n",
      "Train Accuracy:0.8090909090909091\n",
      "Test Accuracy:0.7851851851851852\n"
     ]
    }
   ],
   "source": [
    "# sklearn LR with larger penalty\n",
    "sklearn_larger_penalty = LogisticRegression(random_state=124,C=0.1).fit(X_train, y_train)\n",
    "\n",
    "print(f\"Intercept:{sklearn_larger_penalty.intercept_}  Coefficients: {sklearn_larger_penalty.coef_}\")\n",
    "print(f\"Train Accuracy:{sklearn_larger_penalty.score(X_train,y_train)}\")\n",
    "print(f\"Test Accuracy:{sklearn_larger_penalty.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the best / optimal value for C?\n",
    "\n",
    "We can explore with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimator:LogisticRegression(C=0.01, random_state=124, solver='newton-cg')\n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[0.01,0.1,1,10],'solver':['newton-cg','lbfgs']}\n",
    "Logistic = LogisticRegression(random_state=124)\n",
    "sklearn_GridSearchCV = GridSearchCV(Logistic,parameters)\n",
    "sklearn_GridSearchCV.fit(X_train,y_train)\n",
    "\n",
    "print(f\"best_estimator:{sklearn_GridSearchCV.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:0.8181818181818182\n",
      "Test Accuracy:0.7925925925925926\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy:{sklearn_GridSearchCV.score(X_train,y_train)}\")\n",
    "print(f\"Test Accuracy:{sklearn_GridSearchCV.score(X_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic regression with statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels LR defaults don't have intercept or regularization. It does not include intercept by default. We need to use ```sm.add_constant``` method to include the intercept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.390316\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "X_train_constant = sm.add_constant(X_train)\n",
    "X_test_constant = sm.add_constant(X_test)\n",
    "\n",
    "sm_model_all_predictors = sm.Logit(y_train,X_train_constant).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  330\n",
      "Model:                          Logit   Df Residuals:                      325\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Sun, 11 Sep 2022   Pseudo R-squ.:                  0.4357\n",
      "Time:                        12:39:53   Log-Likelihood:                -128.80\n",
      "converged:                       True   LL-Null:                       -228.25\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.521e-42\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1425      0.159     -0.897      0.370      -0.454       0.169\n",
      "x1             0.5471      1.583      0.346      0.730      -2.556       3.650\n",
      "x2             3.7231      1.566      2.377      0.017       0.653       6.793\n",
      "x3             1.2103      1.568      0.772      0.440      -1.863       4.284\n",
      "x4            -1.8382      1.509     -1.218      0.223      -4.797       1.120\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(sm_model_all_predictors.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.393376\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "sm_model_X1_X2 = sm.Logit(y_train,X_train_constant[:,:3]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  330\n",
      "Model:                          Logit   Df Residuals:                      327\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sun, 11 Sep 2022   Pseudo R-squ.:                  0.4313\n",
      "Time:                        12:39:53   Log-Likelihood:                -129.81\n",
      "converged:                       True   LL-Null:                       -228.25\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.782e-43\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1199      0.157     -0.764      0.445      -0.428       0.188\n",
      "x1             1.7312      0.222      7.791      0.000       1.296       2.167\n",
      "x2             1.8391      0.224      8.215      0.000       1.400       2.278\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(sm_model_X1_X2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can observe that both X1 and X2 are statistically significant.\n",
    "\n",
    "Statsmodels does not have the same accuracy method that we have in sklearn. We will have to use the predict method to predict probabilities. Then we can use the decision rule that probabilities above 0.5 are TRUE and rest are FALSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_train = sm_model_all_predictors.predict(X_train_constant)> 0.5\n",
    "all_predicted_test = sm_model_all_predictors.predict(X_test_constant)> 0.5\n",
    "\n",
    "X1_X2_predicted_train = sm_model_X1_X2.predict(X_train_constant[:,:3])> 0.5\n",
    "X1_X2_predicted_test = sm_model_X1_X2.predict(X_test_constant[:,:3])> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_train_all:0.8151515151515152 and sm_test_all:0.7962962962962963\n",
      "sm_train_x1_x2:0.8121212121212121 and sm_test_x1_x2:0.7888888888888889\n"
     ]
    }
   ],
   "source": [
    "print(f\"sm_train_all:{(y_train == all_predicted_train).mean()} and sm_test_all:{(y_test == all_predicted_test).mean()}\")\n",
    "print(f\"sm_train_x1_x2:{(y_train == X1_X2_predicted_train).mean()} and sm_test_x1_x2:{(y_test == X1_X2_predicted_test).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>default</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>no_penalty</td>\n",
       "      <td>0.815152</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>larger_penalty</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>GridSearchCV</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.792593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>statsmodels</td>\n",
       "      <td>With Intercept + All predictors</td>\n",
       "      <td>0.815152</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>statsmodels</td>\n",
       "      <td>With Intercept + X1 and X2</td>\n",
       "      <td>0.812121</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Library                         Strategy  Train_Accuracy  Test_Accuracy\n",
       "0      sklearn                          default        0.812121       0.785185\n",
       "1      sklearn                       no_penalty        0.815152       0.796296\n",
       "2      sklearn                   larger_penalty        0.809091       0.785185\n",
       "3      sklearn                     GridSearchCV        0.818182       0.792593\n",
       "4  statsmodels  With Intercept + All predictors        0.815152       0.796296\n",
       "5  statsmodels       With Intercept + X1 and X2        0.812121       0.788889"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_list = [['sklearn','default',sklearn_default.score(X_train,y_train),sklearn_default.score(X_test,y_test)],\n",
    "               ['sklearn','no_penalty',sklearn_no_penalty.score(X_train,y_train),sklearn_no_penalty.score(X_test,y_test)],\n",
    "               ['sklearn','larger_penalty',sklearn_larger_penalty.score(X_train,y_train),sklearn_larger_penalty.score(X_test,y_test)],\n",
    "               ['sklearn','GridSearchCV',sklearn_GridSearchCV.score(X_train,y_train),sklearn_GridSearchCV.score(X_test,y_test)],\n",
    "               ['statsmodels','With Intercept + All predictors',(y_train == all_predicted_train).mean(),(y_test == all_predicted_test).mean()],\n",
    "               ['statsmodels','With Intercept + X1 and X2',(y_train == X1_X2_predicted_train).mean(),(y_test == X1_X2_predicted_test).mean()] \n",
    "               ]\n",
    "\n",
    "df = pd.DataFrame(compare_list, columns=['Library','Strategy','Train_Accuracy','Test_Accuracy'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
