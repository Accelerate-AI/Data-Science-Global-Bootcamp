{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19469968",
   "metadata": {},
   "source": [
    "## AccelerateAI Data Science Global Bootcamp\n",
    "\n",
    "### Saving a Trained model for use later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ce1a1",
   "metadata": {},
   "source": [
    "In production, we do not train the model. We only use a trained model.\n",
    "There are multiple ways in which a trained model can be saved for use in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3652e4b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train a simple model \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Read the stock price dataset \n",
    "stock_df = pd.read_csv(\"MLR_Q10_StockPrice.csv\")       \n",
    "\n",
    "# Train a Linear regression model \n",
    "Y = stock_df[\"Stock Price\"]\n",
    "X = stock_df[[\"ROE\", \"Dividend\"]]\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X,Y)\n",
    "\n",
    "#Predict \n",
    "x=[[15,2.5]]\n",
    "lr_model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8561d5",
   "metadata": {},
   "source": [
    "## 1. Save as Pickle \n",
    "Python pickle module is used for serializing and de-serializing a Python object structure. \n",
    "- Any object in Python can be pickled so that it can be saved on disk.\n",
    "- Pickling is a way to convert a python object (including ML models) into a character stream. \n",
    "- This character stream contains all the information necessary to reconstruct the object later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47907a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading library\n",
    "import pickle\n",
    "\n",
    "# create an iterator object with write permission - model.pkl\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(lr_model, files)\n",
    "    \n",
    "# load saved model\n",
    "with open('model_pkl' , 'rb') as f:\n",
    "    lr = pickle.load(f)\n",
    "\n",
    "# check prediction\n",
    "lr.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff767a0",
   "metadata": {},
   "source": [
    "## 2. Save using Joblib\n",
    "\n",
    "Joblib is a set of tools to provide lightweight pipelining in Python. In particular:\n",
    "- transparent disk-caching of functions and lazy re-evaluation \n",
    "- easy simple parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f17984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# saving our model # model - model , filename-model_jlib\n",
    "dump(lr_model, 'model_jlib.joblib') \n",
    "\n",
    "# opening the file- model_jlib\n",
    "m_jlib = load('model_jlib.joblib')\n",
    "\n",
    "# check prediction\n",
    "m_jlib.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e7972",
   "metadata": {},
   "source": [
    "## 3. PMML - Predictive Modeling Markup Language\n",
    "\n",
    "PMML provides a way for analytic applications to describe and exchange predictive models produced by data mining and machine learning algorithms. \n",
    "- PMML is developed by the Data Mining Group (DMG), a consortium of commercial and open-source data mining companies. \n",
    "- PMML is XML-based.The standard was developed in late 1990s, with latest version of PMML,released in December 2011\n",
    "- PMML can help move predictive models from one statistical software to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn2pmml - 2 step process\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets, tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "pipeline = PMMLPipeline(\n",
    "    [\n",
    "        (\n",
    "            \"classifier\",\n",
    "            DecisionTreeClassifier(),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline.fit(iris.data, iris.target)\n",
    "\n",
    "from sklearn2pmml import sklearn2pmml, make_pmml_pipeline\n",
    "sklearn2pmml(pipeline, \"DecisionTree.pmml\", with_repr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7940ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using nyoka - 1 step process\n",
    "from nyoka import skl_to_pmml\n",
    "\n",
    "skl_to_pmml(pipeline, features, target, \"DecisionTree.pmml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ebb22",
   "metadata": {},
   "source": [
    "After the pmml is created, the acccuracy of predictions from the pmml fie can be compared with that from the scikit-learn by using the pypmml library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23752add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypmml import Model\n",
    "import pandas as pd\n",
    "\n",
    "model = Model.fromFile(\"DecisionTree.pmml\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c776e",
   "metadata": {},
   "source": [
    "## 4. Tensorflow \n",
    "\n",
    "A SavedModel contains a complete TensorFlow program, including trained parameters (i.e, tf.Variables) and computation. \n",
    "\n",
    "We can save and load a model in the SavedModel format using the following APIs:\n",
    "- Low-level tf.saved_model API. This document describes how to use this API in detail.\n",
    "  - Save: tf.saved_model.save(model, path_to_dir)\n",
    "  - Load: model = tf.saved_model.load(path_to_dir)\n",
    "- High-level tf.keras.Model API \n",
    "- Keras also supports saving a single HDF5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e646a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a new model instance.\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "model.save(\"my_h5_model.h5\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
